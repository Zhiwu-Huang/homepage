<!DOCTYPE html>
<html>
  <head>
    <title>Zhiwu Huang, Computer Vision Lab, ETH Zurich</title>
    <link href='https://fonts.googleapis.com/css?family=Vollkorn' rel='stylesheet' type='text/css'>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script src="https://code.jquery.com/jquery-1.11.3.min.js"></script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-109828585-1"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'UA-109828585-1');
	</script>
	  
	<script type="text/javascript">
	   function visibility_on(id) {
		var e = document.getElementById(id+"_text");
		if(e.style.display == 'none')
		    e.style.display = 'block';
		var e = document.getElementById(id+"_img");
		if(e.style.display == 'none')
		    e.style.display = 'block';
	   }
	   function visibility_off(id) {
		var e = document.getElementById(id+"_text");
		if(e.style.display == 'block')
		    e.style.display = 'none';
		var e = document.getElementById(id+"_img");
		if(e.style.display == 'block')
		    e.style.display = 'none';
	   }
	   function toggle_visibility(id) {
	       var e = document.getElementById(id+"_text");
	       if(e.style.display == 'inline')
		  e.style.display = 'block';
	       else
		  e.style.display = 'inline';
	       var e = document.getElementById(id+"_img");
	       if(e.style.display == 'inline')
		  e.style.display = 'block';
	       else
		  e.style.display = 'inline';
	   }
	   function toggle_vis(id) {
	       var e = document.getElementById(id);
	       if (e.style.display == 'none')
		   e.style.display = 'inline';
	       else
		   e.style.display = 'none';
	   }
	</script>
	  
	  
	  
    <style>
      body {
      font-family: 'Vollkorn', sans-serif;
      }

      .subheading {
      font-size: 120%;
      }

      h2 {
      clear: left;
      margin-top: 1em;
      }
      
      h3 {
      clear: left;
      margin-top: 1em;
      }
      
      img {
      float: left;
      height: 12em;
      margin-right: 1em;
      margin-bottom: 3em;
      }
     

      p {
      margin: 0.5em;
      }

      nav {
      margin-top: 3em;
      margin-bottom: 1em;
      }
        
        a:visited {color:#006633}
        a:link {color:#006633}
        a:hover {color: #FF0000}
        
        h1,h2,h3{
            color:#006633
        }

    </style>
  </head>
  
  <body>
    <table cellspacing="0"><tr><td width=100%>
    <h1>Zhiwu Huang</h1>
    <div class="subheading">
      <!--<img src="./Photos/ZhiwuHuang-Hawaii.jpeg"/>-->
      <img src="./Photos/ZhiwuHuang-Sydney_2x-9.jpg"/>
      <!--I am a postdoctoral researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> at <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a>, <a href="https://ethz.ch/en.html"> ETH Zurich </a>. My research interest lies in Computer Vision and Machine Learning for Automated Video Artificial Intelligence, capable of automatically learning to understand the world through videos. My research includes applications to deepfakes tracking, affective computing, and autonomous driving. <br><br>-->	
      <!--I am a postdoctoral researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> at <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a>, <a href="https://ethz.ch/en.html"> ETH Zurich </a>. My research studies human-inspired visual intelligence to understand the world through videos, with applications to deepfakes generation & detection, perceptual quality enhancing, affective & behavioural computing, as well as scalable autonomous driving. <br><br>-->
      <!--I am a postdoctoral researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> at <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a>, <a href="https://ethz.ch/en.html"> ETH Zurich </a>. My research studies human-inspired visual intelligence through automated machine learning, with applications to deepfakes generation & detection, perceptual quality enhancing, affective & behavioural computing, as well as scalable autonomous driving. <br><br>-->
      <!--I am a postdoctoral researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> at <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a>, <a href="https://ethz.ch/en.html"> ETH Zurich </a>. My research team (AutoLV, Automated Learning in Vision) studies human-inspired visual intelligence through automated machine learning on data, label, feature, neuron and task. The applications include visual deepfake, affect and behavior computing. <br><br>-->
      I am a postdoctoral researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> at <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a>, <a href="https://ethz.ch/en.html"> ETH Zurich </a>. My research team (AutoLV) studies automated learning in vision that aims for making machines to learn the visual world, all by themselves. The current research focus is on visual fake, affect and behavior computing through automated machine learning on data, label, feature, neuron and task. <br><br>
    	    
      <!--I currently working on video generation, enhancement and manipulation as well as human-focussed video clustering, classification, prediction with deep manifold learning, generative distribution learning, and neural architecture learning.-->
      I will be starting as an Assistant Professor in the <a href="https://sis.smu.edu.sg"> School of Computing and Information Systems <a> at <a href="https://www.smu.edu.sg"> Singapore Management University (SMU) </a> in Summer of 2021. Please follow the <a href="position.html"> instructions </a> to reach me if you are interested in joining my research group as a Ph.D. student. <br>
	     
      <!--<b> [<a href="http://scholar.google.ch/citations?user=yh6t92AAAAAJ&hl=en">Google Scholar</a>] [<a href="https://github.com/zhiwu-huang"> Github </a>] </b> -->
      
       <!-- <b>Prospective students </b>, please <a href="javascript:toggle_vis('contact')">read this</a> before contacting me.
              <div id="contact" style="display:none"> 
                  Thank you for your interest in joining my research team! I am taking on new MS and PhD students each year. However, I ask that you do not contact me directly with regard to MS or PhD admissions until after you are admitted, as I will not be able to reply to individual emails. <br>
                  If you are interested in a <i>post-doc</i> position, please read <a href="https://goo.gl/forms/aKL2gnq8T80FNVMb2">this form</a>. <br>
                  If you are a current or admitted <i>ETH MS student</i> interested in research positions, please read <a href="https://goo.gl/forms/uJuYOfIBQVPhEEDy1">this form</a>. <br>
                  If you are not an ETH student and insteresed in research positions, please read <a href="https://goo.gl/forms/9scJRH3hw6z7GNbj2">this form</a>.
              </div>
        </p>-->
        
    </div>
    

    <nav>
      Jump to: 
      <a href="index.html#Projects">Research</a> |
      <a href="publication.html">Publications</a> |
      <a href="workshop.html">Workshops </a> |
      <a href="talk.html">Talks</a> |
      <a href="teaching.html">Teaching</a> |
      <a href="position.html">Opening positions</a> | 
      <a href="about.html">About me</a> | 
      <a href="contact.html">Contact</a>
    </nav>
      
    <!--<h2>Publications</h2>-->

      <h2>arXiv and Tech Reports</h2>
	    
      <p> Aoming Liu, Zehao Huang, <b>Zhiwu Huang</b>, Naiyan Wang. Direct Differentiable Augmentation Search. <em> <a href="https://arxiv.org/abs/2104.04282"> arXiv preprint arXiv:2104.04282 </a>, 2021. </em> <b> (Automated Data Augmentation Learning for Object Classification and Detection) </b> </p>  
	    	    
      <p> Yan Wu, <b>Zhiwu Huang</b>, Suryansh Kumar, Rhea Sanjay Sukthanker, Radu Timofte, Luc Van Gool. Trilevel Neural Architecture Search for Efficient Single Image Super-Resolution. <em> <a href="https://arxiv.org/abs/2101.06658"> arXiv preprint arXiv:2101.06658 </a>, 2021. </em> <b> (Automated Neuron Learning for Deepfake Computing) </b> </p>  
	    
      <p> Dario Fuoli, <b>Zhiwu Huang</b>, Danda Pani Paudel, Luc Van Gool, Radu Timofte. An Efficient Recurrent Adversarial Framework for Unsupervised Real-Time Video Enhancement. <em> <a href="https://arxiv.org/abs/2012.13033"> arXiv preprint arXiv:2012.13033 </a>, 2020. </em> <b> (Automated Data Learning for Deepfake Computing) </b> </p>
      
      <!--<p> <b>Zhiwu Huang</b>, Danda Pani Paudel, Guanju Li, Jiqing Wu, Radu Timofte, Luc Van Gool. Divide-and-Conquer Adversarial Learning for High-Resolution Image and Video Enhancement. <em> <a href="https://arxiv.org/abs/1910.10455"> arXiv preprint arXiv:1910.10455</a>, 2019. </em>  </p> --> 
      
      <!--<p> Dinesh Acharya, <b>Zhiwu Huang</b>, Danda Pani Paudel, Luc Van Gool. Towards High Resolution Video Generation with Progressive Growing of Sliced Wasserstein GANs. <em>  <a href="https://arxiv.org/abs/1810.02419"> arXiv preprint arXiv:1810.02419 </a>, 2018. </em> </p> -->

      <h2>Selected Publication</h2> 
    
      <!-- <h2>2020</h2>-->
      <p> Rhea Sanjay Sukthanker, <b>Zhiwu Huang</b>, Suryansh Kumar, Erik Goron Endsjo, Yan Wu, Luc Van Gool. Neural Architecture Search of SPD Manifold Networks. In <em> International Joint Conference on Artificial Intelligence (IJCAI), 2021. (Accepted) </em>. <a href="https://arxiv.org/pdf/2010.14535.pdf"> Preprint </a> <b> (Automated Neuron Learning for Affective and Behavioral Computing) </b> </p>  
    
      <p> Mohamad Shahbazi, <b>Zhiwu Huang</b>, Danda Pani Paudel, Ajad Chhatkuli, Luc Van Gool. Efficient Conditional GAN Transfer with Knowledge Propagation across Classes. In <em> Computer Vision and Pattern Recognition (CVPR), 2021. (Accepted) </em>. <a href="https://arxiv.org/pdf/2102.06696.pdf"> Preprint </a> | <a href="https://github.com/mshahbazi72/cGANTransfer"> Code </a> <b> (Automated Task Learning for Deepfake Computing) </b>   </p>
	    
      <p> Stefano D'Apolito, Danda Pani Paudel, <b>Zhiwu Huang</b>, Andres Romero Vergara, Luc Van Gool. GANmut: Learning Interpretable Conditional Space for Gamut of Emotions. In <em> Computer Vision and Pattern Recognition (CVPR), 2021. (Accepted) </em>. <a href="./Papers/GANmut_CVPR2021.pdf"> Preprint </a> | <a href="https://github.com/stefanodapolito/GANmut"> Code </a> | Project Page <b> (Automated Label Learning for Affective Computing) </b> </p>

      <p> Anton Obukhov, Maxim Rakhuba, Alexander Liniger, <b>Zhiwu Huang</b>, Stamatios Georgoulis, Dengxin Dai, Luc Van Gool. Spectral Tensor Train Parameterization of Deep Learning Layers. In <em> International Conference on Artificial Intelligence and Statistics (AISTATS), 2021. </em> <a href="https://arxiv.org/pdf/2103.04217.pdf"> Preprint </a> | <a href="https://www.obukhov.ai/sttp"> Project Page </a> <b> (Automated Neuron Learning for Deepfake Computing) </b> </p>
   
      <p> Yan Wu*, Aoming Liu*, <b>Zhiwu Huang</b>, Siwei Zhang, Luc Van Gool. <em> (*indicates equal contributions) </em>. Neural Architecture Search as Sparse Supernet. In <em> Association for the Advancement of Artificial Intelligence (AAAI), 2021 </em>. <a href="https://arxiv.org/pdf/2007.16112.pdf"> Preprint </a> | <a href="./Videos/sparsenas_aaai2021_short.mp4"> Oral Presentation (short) </a> <b> (Automated Neuron Learning for Object Classification) </b> </p>  

      <p> Siwei Zhang, <b>Zhiwu Huang</b>, Danda Pani Paudel, Luc Van Gool. Facial Emotion Recognition with Noisy Multi-task Annotations. In <em> Winter Conference on Applications of Computer Vision (WACV), 2021 </em>.  <a href="https://arxiv.org/pdf/2010.09849.pdf"> Preprint </a> | <a href="https://github.com/sanweiliti/noisyFER"> Code </a> | <a href="./Videos/noisyFER_WACV2021.mp4"> Oral Presentation </a> <b> (Automated Label Learning for Affective Computing) </b> </p> 
	    
      <p> Dario Fuoli, <b>Zhiwu Huang</b>, Radu Timofte and et al.  AIM 2020 Challenge on Video Extreme Super-Resolution: Methods and Results. In <em> European Conference on Computer Vision (ECCV) workshop, 2020 </em>. <a href="./Papers/ECCV_2020__AIM2020_VXSR.pdf">Paper </a> | <a href="./Videos//aim2020vxsr.mp4"> Oral Presentation </a> </p>
    
      <p> Marc Yanlong Zhang, <b>Zhiwu Huang</b>, Danda Pani Paudel, Janine Thoma, Luc Van Gool. Weakly Paired Multi-Domain Image Translation. In <em> British Machine Vision Conference (BMVC), 2020. (Oral). </em> <a href="./Papers//BMVC2020_WeaklyPaired.pdf"> Paper </a> | <a href="./Papers//BMVC2020_WeaklyPaired_suppl.pdf"> Supp </a> | <a href="https://www.bmvc2020-conference.com/conference/papers/paper_0841.html"> Oral Presentation </a> <b> (Automated Data Learning for Autonomous Driving) </b>   </p>
	      
      <p> Yuan Tian*, Qin Wang*, <b>Zhiwu Huang</b>, Wen Li, Dengxin Dai, Minghao Yang, Jun Wang, Olga Fink. <em> (*indicates equal contributions) </em>. Off-Policy Reinforcement Learning for Efficient and Effective GAN Architecture Search. In <em> European Conference on Computer Vision (ECCV), 2020 </em>. <a href="https://arxiv.org/pdf/2007.09180.pdf"> Paper </a> | <a href="https://github.com/Yuantian013/E2GAN"> Code </a> | <a href="https://youtu.be/0iBHFzs9sgY"> Oral Presentation </a> <b> (Automated Neuron Learning for Deepfake Computing) </b>  </p> 
 
      <p> Dario Fuoli, <b>Zhiwu Huang</b>, Martin Danelljan, Radu Timofte and et al. NTIRE 2020 Challenge on Video Quality Mapping: Methods and Results. In <em> Computer Vision and Pattern Recognition (CVPR) workshop, 2020. </em> <a href="https://arxiv.org/pdf/2005.02291.pdf">Paper</a> | <a href="./Talks/NTIRE2020ChallengeVideoQualityMapping_20200615.pdf"> Slides </a> </p>
      

      <!-- <h2>2019</h2>-->
      
      <p> Sohyeong Kim, Guanju Li, Dario Fuoli, Martin Danelljan, <b>Zhiwu Huang</b>, Shuhang Gu, Radu Timofte. The Vid3oC and IntVID Datasets for Video Super Resolution and Quality Mapping. In <em>  International Conference on Computer Vision (ICCV) workshop, 2019 </em>. <a href="http://www.vision.ee.ethz.ch/~timofter/publications/Kim-ICCVW-2019.pdf">Paper</a> 
      
      <p> Jiqing Wu*, <b>Zhiwu Huang*</b>, Dinesh Acharya, Wen Li, Janine Thoma, Danda Pani Paudel,  Luc Van Gool. <em> (*indicates equal contributions) </em>. Sliced Wasserstein Generative Models. In <em> Computer Vision and Pattern Recognition (CVPR), 2019 </em>. <a href="https://arxiv.org/pdf/1706.02631.pdf">Paper</a> | <a href="https://github.com/musikisomorphie/swd">Code</a> <b> (Automated Data Learning for Deepfake Computing) </b> <br>
	  <b> Extension:</b> Dinesh Acharya, <b>Zhiwu Huang</b>, Danda Pani Paudel, Luc Van Gool. Towards High Resolution Video Generation with Progressive Growing of Sliced Wasserstein GANs. <em>  <a href="https://arxiv.org/abs/1810.02419"> arXiv preprint arXiv:1810.02419 </a>, 2018. </em> 

      </p>

      <!-- <p> <b>Zhiwu Huang</b>, Jiqing Wu, Luc Van Gool. Manifold-valued Image Generation with Wasserstein Generative Adversarial Nets. In <em> Association for the Advancement of Artificial Intelligence (AAAI),  2019 </em>. <a href="https://arxiv.org/pdf/1712.01551.pdf">Paper</a> -->

      <!-- <h2>2018</h2>-->

      <p> Jiqing Wu, <b>Zhiwu Huang</b>, Janine Thoma, Dinesh Acharya, Luc Van Gool. Wasserstein Divergence for GANs. In <em> European Conference on Computer Vision (ECCV), 2018 </em>. <a href="https://arxiv.org/pdf/1712.01026.pdf">Paper</a> | <a href="https://github.com/musikisomorphie/wgan-div">Code</a>  <b> (Automated Data Learning for Deepfake Computing) </b>
	     
      <!--<p> Dinesh Acharya, <b>Zhiwu Huang</b>, Danda Pani Paudel, Luc Van Gool. Covariance Pooling for Facial Expression Recognition. In <em> Computer Vision and Pattern Recognition (CVPR) workshop, 2018 </em>. <a href="https://arxiv.org/pdf/1805.04855.pdf">Paper</a> | <a href="https://github.com/d-acharya/CovPoolFER">Code</a>  <b> (Automated Feature Learning for Affective Computing) </b> -->

      <p> <b>Zhiwu Huang</b>, Jiqing Wu,  Luc Van Gool. Building Deep Networks on Grassmann Manifolds. In <em> Association for the Advancement of Artificial Intelligence (AAAI), 2018 </em>. <a href="https://arxiv.org/pdf/1611.05742.pdf">Paper</a> | <a href="https://github.com/zzhiwu/GrNet">Code</a> <b> (Automated Feature Learning for Affective and Behavioral Computing) </b> 

      <!-- <p> <b>Zhiwu Huang</b>, Ruiping Wang, Shiguang Shan, Luc Van Gool, Xilin Chen. Cross Euclidean-to-Riemannian Metric Learning with Application to Face Recognition from Video. <em>  IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2018 </em>. <a href="http://arxiv.org/pdf/1608.04200.pdf">Paper</a>
	      
      <p> Wen Wang, Ruiping Wang, <b>Zhiwu Huang</b>, Shiguang Shan, Xilin Chen. Discriminant Analysis on Riemannian Manifold of Gaussian Distributions for Face Recognition with Image Sets. <em>  IEEE Transactions on Image Processing (TIP), 2018 </em>. <a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8022922">Paper</a> -->
   
      <!-- <h2>2017</h2>-->
      
      <p> <b>Zhiwu Huang</b>, Chengde Wan, Thomas Probst, Luc Van Gool. Deep Learning on Lie Groups for Skeleton-based Action Recognition. In <em> Computer Vision and Pattern Recognition (CVPR), 2017. (Spotlight) </em>. <a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Deep_Learning_on_CVPR_2017_paper.pdf">Paper</a> | <a href="https://github.com/zzhiwu/LieNet">Code</a> <b> (Automated Feature Learning for Behavioral Computing) </b>

      <p> <b>Zhiwu Huang</b> and Luc Van Gool. A Riemannian Network for SPD Matrix Learning. In <em> Association for the Advancement of Artificial Intelligence (AAAI), 2017 </em>. <a href="https://arxiv.org/pdf/1608.04233.pdf">Paper</a> | <a href="https://github.com/zzhiwu/SPDNet-master">Code</a> <b> (Automated Feature Learning for Affective and Behavioral Computing) </b> </br>  
	  <b> Extension:</b> Dinesh Acharya, <b>Zhiwu Huang</b>, Danda Pani Paudel, Luc Van Gool. Covariance Pooling for Facial Expression Recognition. In <em> Computer Vision and Pattern Recognition (CVPR) workshop, 2018 </em>. <a href="https://arxiv.org/pdf/1805.04855.pdf">Paper</a> | <a href="https://github.com/d-acharya/CovPoolFER">Code</a>  

      </p>

      <!--<p> <b>Zhiwu Huang</b>, Ruiping Wang, Xianqiu Li, Wenxian Liu, Shiguang Shan, Luc Van Gool, Xilin Chen. Geometry-aware Similarity Learning on SPD Manifolds for Visual Recognition. <em> IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2017</em>. <a href="http://arxiv.org/pdf/1608.04914.pdf"> Paper </a> -->

      <!--<h2> Before 2017 </h2> 
	    
      <p><b>Can be found on <a href="https://scholar.google.ch/citations?user=yh6t92AAAAAJ&hl=en" target="new">Google Scholar</a></b></p>-->
      
      <h2> <a href="https://scholar.google.ch/citations?user=yh6t92AAAAAJ&hl=en" target="new"> Full Publication </a> </h2>



     
</body>

</html>
