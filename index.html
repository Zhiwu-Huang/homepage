<!DOCTYPE html>
<html>
  <head>
    <title>Zhiwu Huang, Postdoc in Computer Vision and Machine Learning, ETH Zurich </title>
    <link href='https://fonts.googleapis.com/css?family=Vollkorn' rel='stylesheet' type='text/css'>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script src="https://code.jquery.com/jquery-1.11.3.min.js"></script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-109828585-1"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'UA-109828585-1');
	</script>
	  
	<script type="text/javascript">
	   function visibility_on(id) {
		var e = document.getElementById(id+"_text");
		if(e.style.display == 'none')
		    e.style.display = 'block';
		var e = document.getElementById(id+"_img");
		if(e.style.display == 'none')
		    e.style.display = 'block';
	   }
	   function visibility_off(id) {
		var e = document.getElementById(id+"_text");
		if(e.style.display == 'block')
		    e.style.display = 'none';
		var e = document.getElementById(id+"_img");
		if(e.style.display == 'block')
		    e.style.display = 'none';
	   }
	   function toggle_visibility(id) {
	       var e = document.getElementById(id+"_text");
	       if(e.style.display == 'inline')
		  e.style.display = 'block';
	       else
		  e.style.display = 'inline';
	       var e = document.getElementById(id+"_img");
	       if(e.style.display == 'inline')
		  e.style.display = 'block';
	       else
		  e.style.display = 'inline';
	   }
	   function toggle_vis(id) {
	       var e = document.getElementById(id);
	       if (e.style.display == 'none')
		   e.style.display = 'inline';
	       else
		   e.style.display = 'none';
	   }
	</script>
	  
	  
	  
    <style>
      body {
      font-family: 'Vollkorn', sans-serif;
      }

      .subheading {
      font-size: 120%;
      }

      h2 {
      clear: left;
      margin-top: 1em;
      }
      
      h3 {
      clear: left;
      margin-top: 1em;
      }
      
      img {
      float: left;
      height: 12em;
      margin-right: 1em;
      margin-bottom: 3em;
      }

      p {
      margin: 0.5em;
      }

      nav {
      margin-top: 3em;
      margin-bottom: 1em;
      }
        
        a:visited {color:#006633}
        a:link {color:#006633}
        a:hover {color: #FF0000}
        
        h1,h2,h3{
            color:#006633
        }

    </style>
  </head>
  
  <body>
    <table cellspacing="0"><tr><td width=100%>
    <h1>Zhiwu Huang</h1>
    <div class="subheading">
      <img src="ZhiwuHuang-Hawaii.jpg"/>
      I am a postdoctoral researcher under the supervision of Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> at <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a>, ETH Zurich. My research interest lies in Computer Vision and Machine Learning for <b> Automated Video Artificial Intelligence, </b> capable of autmatically learning to understand the world through videos. I currently working on human-focussed video clustering, classification, prediction as well as video generation, enhancement and manipulation with deep manifold learning, generative distribution learning, and neural architecture learning.<br><br>	
      <b>[<a href="https://vision.ee.ethz.ch/people-details.MjIwNDU5.TGlzdC8zMjkyLC0xOTcxNDY1MTc4.html">Contact Details</a>] [<a href="http://scholar.google.ch/citations?user=yh6t92AAAAAJ&hl=en">Google Scholar</a>] </b>		
        
    </div>
    

    <nav>
      Jump to: 
      <a href="index.html#Projects">Research</a> |
      <a href="publications.html">Publications</a> |
      <a href="code.html">Datasets and code</a> |
      <a href="talks.html">Talks</a> |
      <a href="teaching.html">Teaching</a> |
      <a href="about.html">About me</a> |
      <a href="contact.html">Contact</a>
    </nav>
	    
    <h2>News</h2>
                <li> 07/2020, One paper "Off-Policy Reinforcement Learning for Efficient and Effective GAN Architecture Search" is accepted by ECCV 2020. </li>
	 	<li> 05/2020, We are organizing <a href= "https://competitions.codalab.org/competitions/24685"> AIM Video Super-Resolution Challenge </a> @ECCV 2020. </li>
 		<li> 05/2020, One paper "NTIRE 2020 Challenge on Video Quality Mapping: Methods and Results" will appear at the workshop NTIRE in conjunction with CVPR 2020. </li>
    		<li> 12/2019, We are organizing <a href= "https://competitions.codalab.org/competitions/20247"> NTIRE Video Quality Mapping Challenge </a> @CVPR 2020. </li>
    		<li> 10/2019, One dataset paper "The Vid3oC and IntVID Datasets for Video Super Resolution and Quality Mapping" will appear at the workshop AIM in ICCV 2019. </li>
		<li>10/2019, We are organizing a workshop <a href= "http://www.vision.ee.ethz.ch/aim19/"> "AIM: Advances in Image Manipulation workshop and challenges on image and video manipulation" </a>
  and a tutorial <a href= "http://www.vision.ee.ethz.ch/fire19/index_fire19.html"> "FIRE: From Image Restoration to Enhancement and Beyond" </a> at ICCV, Oct. 27, 2019. </li>

		<li>02/2019, One paper "Sliced Wasserstein Generative Models" is accepted by CVPR 2019. This paper was selected as one of the BEST PUBLICATIONS of the week (20.04.2019), by DeepAI. <a  href="https://deepai.org/publication/sliced-wasserstein-generative-models"> Link to DeepAI Website </a> </li>

		<li> <a href="javascript:toggle_vis('news')"> Older news...</a> </li>
		<div id="news" style="display:none"> 
			<li>11/2018, One paper "Manifold-valued Image Generation with Wasserstein Generative Adversarial Nets" is accepted by AAAI 2019. <em> This paper applies the theory of optimal transport on non-compact manifolds from Alessio Figalli (2018 Fields Medal winner) to generative modeling, which is able to generate photo-realistic biological samples. </em> </li>
	<!--<b> The paper applies the theory of optimal transport on non-compact manifolds from Alessio Figalli, who won 2018 Fields Medal. </b> -->
			<li>07/2018, One paper "Wasserstein Divergence for GANs" is accepted by ECCV 2018.</li>
			<li>04/2018, One paper "Covariance Pooling for Facial Expression Recognition" is accepted by the workshop DiffCVML in CVPR 2018.</li>
			<li>11/2017, One paper "Cross Euclidean-to-Riemannian Metric Learning with Application to Face Recognition from Video" is accepted as a Regular Paper in IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI).</li>
			<li>11/2017, One paper "Building Deep Networks on Grassmann Manifolds" (GrNet) is accepted by AAAI 2018.</li>
		    <li>08/2017, One paper "Discriminant Analysis on Riemannian Manifold of Gaussian Distributions for Face Recognition with Image Sets" is accepted by IEEE Transactions on Image Processing (TIP).</li>
			<li>07/2017, One paper "Geometry-aware Similarity Learning on SPD Manifolds for Visual Recognition" is accepted by IEEE Transactions on Circuits and Systems for Video Technology (TCSVT).</li>
			<li>02/2017, One paper "Deep Learning on Lie Groups for Skeleton-based Action Recognition" (LieNet) is accepted as a spotlight by CVPR 2017. <em> This paper proposes deep networks of Lie Groups for skeleton-based action recognition. </em> </li>
		    <li>11/2016, One paper "A Riemannian Network for SPD Matrix Learning" (SPDNet) is accepted by AAAI 2017. <em>  This paper opens a new direction of deep manifold networks. </em> </li>
	     	</div>	

          </td>
    </tr></table>
    
    <a name="Projects"><h2>Research Projects</h2></a>

    <h3><a href="https://github.com/musikisomorphie/swd">Video Generation</a></h3>
          <table><tr>
		  
		  <td width="40%">  <a href="https://github.com/musikisomorphie/swd"><video autoplay muted loop width="100%">
			  <!--<source src="https://epic-kitchens.github.io/static/videos/04x04_vp9.webm" type="video/webm">-->
			  <source src="trailerfaces_generation_cropped.mp4" type="video/mp4">
			  <source src="trailerfaces_generation_cropped.mp4" type="video/mp4">
			  Sorry, we cannot display the generated video wall as
			  your browser doesn't support HTML5 video.
                  </video></a></td>
		  
		<td valign="top">
		<p><a href="https://github.com/musikisomorphie/swd"> Source Code </a> | <a href="https://data.vision.ee.ethz.ch/zzhiwu/trailerFaces-tfrecords.zip"> TrailerFace Dataset </a> 
	    	<p> Sliced Wasserstein Generative Models. <a href="https://scholar.google.ch/citations?user=BCKKfUEAAAAJ&hl=en"> Jiqing Wu* </a>, <b>Zhiwu Huang*</b>,  <a href="https://www.researchgate.net/scientific-contributions/2142556529_Dinesh_Acharya"> Dinesh Acharya </a>, <a href="https://scholar.google.com/citations?user=yjG4Eg4AAAAJ&hl=en"> Wen Li </a>, <a href="https://scholar.google.ch/citations?user=NpZj7TAAAAAJ&hl=en"> Janine Thoma </a>, <a href="https://scholar.google.ch/citations?user=W43pvPkAAAAJ&hl=en"> Danda Pani Paudel </a>,  <a href="https://scholar.google.com/citations?user=TwMib_QAAAAJ&hl=en"> Luc Van Gool </a>. <em> (*indicates equal contributions) </em>                
			 <em> Computer Vision and Pattern Recognition (CVPR), 2019 </em>. <a href="https://arxiv.org/abs/1706.02631">Paper</a></p>
	        <p>Towards High Resolution Video Generation with Progressive Growing of Sliced Wasserstein GANs. <a href="https://www.researchgate.net/scientific-contributions/2142556529_Dinesh_Acharya"> Dinesh Acharya </a>, <b>Zhiwu Huang</b>, <a href="https://scholar.google.ch/citations?user=W43pvPkAAAAJ&hl=en"> Danda Pani Paudel </a>, <a href="https://scholar.google.com/citations?user=TwMib_QAAAAJ&hl=en"> Luc Van Gool </a>.  
			 <em>  <a href="https://arxiv.org/abs/1810.02419"> arXiv:1810.02419 </a>, 2018 </em> </p>
		<p>Improving Video Generation for Multi-functional Applications. <a href="https://scholar.google.ch/citations?user=zYjOhRUAAAAJ&hl=en"> Bernhard Kratzwald </a>, <b>Zhiwu Huang</b>, <a href="https://scholar.google.ch/citations?user=W43pvPkAAAAJ&hl=en"> Danda Pani Paudel </a>,  <a href="https://www.researchgate.net/scientific-contributions/2142556529_Dinesh_Acharya"> Dinesh Acharya </a>, <a href="https://scholar.google.com/citations?user=TwMib_QAAAAJ&hl=en"> Luc Van Gool </a>. <em>  <a href="https://arxiv.org/abs/1711.11453"> arXiv:1711.11453 </a>,  <a href="https://bernhard2202.github.io/ivgan/index.html"> Project Page </a> 2017 </em> </p>
        </td></tr></table>
	  
     <h3><a href="https://competitions.codalab.org/competitions/20247">Video Enhancement</a></h3>
	    <a href="ideo_enhancement_demo.jpg"><img src="video_enhancement_demo.jpg" /></a>
	    <p><a href="https://competitions.codalab.org/competitions/20247"> Video Quality Mapping Challenge </a></p> 
	    <p>Who's Better? Who's Best? Pairwise Deep Ranking for Skill Determination. H Doughty, D Damen, W Mayol-Cuevas. CVPR (2018). <a href="Skill/whos_better_whos_best.pdf">PDF</a> | <a href="https://arxiv.org/abs/1703.09913">arxiv</a> | <a href="./Skill/index.html#dataset">Dataset</a>
	    </p>

    

	    
   </body>
</html>
